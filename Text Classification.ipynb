{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ffda96-6120-4d25-9e55-d9ccbac283c3",
   "metadata": {},
   "source": [
    "### Introduction to Text Classification\n",
    "Text Classification is a Natural Language Processing task where text is analyzed, understood and categorized into predefined classes or categories.\n",
    "\n",
    "It involves assigning a label or category to a given piece of text based on its context. \n",
    "\n",
    "- Categorizing text into predefined categories based on its content.\n",
    "- Examples:\n",
    "   - Email filtering (spam vs. not spam)\n",
    "   - Sentiment analysis (positive, negative, neutral)\n",
    "   - News Categorization(politics, sports, technology)\n",
    "- Importance : Automates the understanding of large valumes of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14902ee2-07fe-41a2-8128-4f26f99f630f",
   "metadata": {},
   "source": [
    "#### Application of Text Classification\n",
    "- Sentiment Analysis\n",
    "- Document Classification\n",
    "- Spam Detection\n",
    "- Language Detection\n",
    "- Customer Support\n",
    "-Search Engine Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5578adf-3877-4bfb-9ef3-21c72ff403fc",
   "metadata": {},
   "source": [
    "#### Methods used in Text Classification\n",
    "- Rule Based Systems\n",
    "- Machine Learning Models\n",
    "- Deep Learning Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb2828-bc9e-4263-9f34-6ca17cd71a8a",
   "metadata": {},
   "source": [
    "#### Building a Text Classisfication using different librarires\n",
    "1. Import library\n",
    "2. Load and preprocess text data\n",
    "3. Feature extraction using Bag of Words or TF-IDF\n",
    "4. Train a simple Naive Bayes classifier\n",
    "5. Test and evaluate the classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16af8d7-6d6c-471a-81f7-075dfc50ef1b",
   "metadata": {},
   "source": [
    "#### spaCy:\n",
    "- Built for production-level tasks and focuses on efficiency and performance. It is optimized for industrial use cases, handling large-scale data and real-time NLP applications.\n",
    "- Known for its speed and efficiency\n",
    "- For advnaced preprocessing like lemmatization, POS tagging, dependency parsing, named entity recognition (NER) and word embeddings.\n",
    "\n",
    "- spaCy 101 A brief introduction\n",
    "- spaCy Course Advanced NLP with spaCy\n",
    "\n",
    "Text Classification with spaCy\n",
    "-Load spaCy and process text\n",
    "- Extract linguistic features (POS, entities, etc)\n",
    "- Train a classifier using features\n",
    "- Evaluate the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20bce8-22a2-41cc-9065-6b1bc424bca5",
   "metadata": {},
   "source": [
    "# Text Classification with NLTK [Natural language ToolKit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7941cc3c-7dc1-4a58-8de7-d6210390cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c122e7-92ef-47db-bc91-58eb34da6877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\sandh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30d57ff-4a23-44d0-b989-18554d04d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec2adb6-f2af-4b6c-8af0-f84577f75bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sandh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f06d506-c681-4322-8c1d-0b92a3b55f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"I love this movie\", \"pos\"),\n",
    "    (\"Good and Nice acting\", \"pos\"),\n",
    "    (\"Boring and Terrible\", \"neg\"),\n",
    "    (\"Bad acting and I hated this\", \"neg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98858c8-af1a-45f0-a10c-959dabf157bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'this', 'movie']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(\"I love this movie\".lower())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f0970d-d163-45e8-91f2-fe99b8971442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8b44ae-56a8-41cf-8739-c22ee86908cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'movie']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_revised = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "words_revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8505a0-9ec6-49ef-b1d5-3a1ae4862619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sentence):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    # (sentence.lower() -> I love this movie\n",
    "    # words = word_tokenize(sentence.lower()) # [\"I\", \"love\", \"this\", \"movie\"]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_revised = [word for word in words if word.isalpha() and word not in stop_words] # Remove punctuations [! , . ; \"\" ''] and stop words\n",
    "    return {word: True for word in words_revised}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ffd823-18a4-45df-be8c-2ecefb24d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': True, 'movie': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(\"I love this movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d515c8b1-fd65-4ef6-96af-96d91e1525a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'love': True, 'movie': True}, 'pos'),\n",
       " ({'good': True, 'nice': True, 'acting': True}, 'pos'),\n",
       " ({'boring': True, 'terrible': True}, 'neg'),\n",
       " ({'bad': True, 'acting': True, 'hated': True}, 'neg')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training_data into feature sets\n",
    "training_features = [(extract_features(sentence), label) for sentence, label in training_data]\n",
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f308bb-2f0e-438e-8452-59b577a1a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"I love this movie\", \"pos\"),\n",
    "    (\"Good and Nice acting\", \"pos\"),\n",
    "    (\"Boring and Terrible\", \"neg\"),\n",
    "    (\"Bad acting and I hated this\", \"neg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c49f90f6-9a33-4d90-8cb4-8ccfd1d9463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0489f67-7b44-4c81-9cf4-f545dbffbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"I really enjoyed this movie\"\n",
    "    \"Boring and Terrible\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d828b523-70ad-4587-8de8-469d42259452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:'I really enjoyed this movieBoring and Terrible' => Predicted Sentiment: neg\n"
     ]
    }
   ],
   "source": [
    "for t_sent in test_sentences:\n",
    "    f_extract = extract_features(t_sent)\n",
    "    predicted_label = classifier.classify(f_extract)\n",
    "    print(f\"Sentence: '{t_sent}' => Predicted Sentiment: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5245a9e6-878b-4c29-9f63-1b47f07ac186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
