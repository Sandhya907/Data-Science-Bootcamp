{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9068a87-747c-4f08-8b1c-ce7138538aa2",
   "metadata": {},
   "source": [
    "### Introduction to Big Data\n",
    "Examples:\n",
    "- Social Media platforms store and analyze user interactions to personalize feeds.\n",
    "- Online shopping websites use data to recommend products you might like.\n",
    "- Traffic management systems use lot devices to monitor and predict congestion in real time.\n",
    "- Weather forecasting uses massive datasets from sensors and satellites to make accurate predcitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cae968-6177-40bc-8baf-c9dc15d9ff20",
   "metadata": {},
   "source": [
    "### Big Data\n",
    "- It refers to dataset that are so large, fast or complex that traditional data processing methods cannot handle them effectively.\n",
    "\n",
    "- These datasets require specialized tools and techniques to store, process and anlayze. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c149b4f-ff7a-48a1-a90e-9ad0a7f6efb0",
   "metadata": {},
   "source": [
    "### Why is Big Data important?\n",
    "- Gain deeper insights into complex problems.\n",
    "- Make informed decisions in real time.\n",
    "- Build innovative solutions like recommendation systems, fraud detection, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1393b4-760c-4a13-b80e-c170338264f5",
   "metadata": {},
   "source": [
    "### The Five V's of Big Data\n",
    "To better understand Big Data, we use the Five V's framework. Each \"V\" represents a key characteristics that defines Big Data\n",
    "\n",
    "1. Volume:\n",
    "- The amount of data generated is enormous, often measure in terabytes or even perabytes.\n",
    "- Example: Social media platforms like Twitter and Instagram generate terabytes of data daily through posts like an\n",
    "\n",
    "2. Velocity:\n",
    "- The speed at which data is generated and needs to be processed.\n",
    "- Example:Stock market systems generate data in milliseconds, requiring real-time analysis to make predictions and decisions.\n",
    "\n",
    "3. Variety:\n",
    "- Data comes in multiple formats, including:\n",
    "  - Structured: Tabular data in databases.\n",
    "  - Unstructured: Text, images, videos, etc.\n",
    "  - Semi-structured: JSON, XML, etc\n",
    "\n",
    "- Example: A company might analyze customer emails(text), product images(pictures), and transaction records(structured data).\n",
    "\n",
    "4. Veracity: \n",
    "- Refers to the uncertainty or accuracy of the data.\n",
    "- Cleaning and validating noisy or incomplete data are critical for meanigful insights.\n",
    "- Example: Customer reviews often have typos or inconsistencies taht need to be addressed before analysis.\n",
    "\n",
    "5. Value: \n",
    "- The ultimate goal of Big Data is to derive value, insights that drive better decisions or create innovative solutions.\n",
    "- Example: E-commerce websited use data to create personalized product recommendations leading to improved user experiences and increased sales.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083ff07-4367-4547-b49f-f738e9bcb569",
   "metadata": {},
   "source": [
    "### Real-World Applications of Big Data\n",
    "\n",
    "1. Healthcare:\n",
    "- Predict patient outcome by analyzing data from electronic medical record(EMRs), wearable devices, and diagnostic tools.\n",
    "- Example: Use Big Data to detect early signs of diseases like Cancer through pattern recognition.\n",
    "\n",
    "2. E-commerce:\n",
    "- Personalized recommendations are pewered by analyzing user behaviour, search history, and purchase patterns.\n",
    "- Example: Amazon suggests products based on your browsing and purchasing history.\n",
    "\n",
    "3. Smart Cities:\n",
    "- Manage traffic, energy, and public services using loT sensors and Big Data analytics.\n",
    "- Example: Smart traffice lights adjust timings based on real-time traffic data to reduce congestion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217effea-9269-400d-8851-647432975777",
   "metadata": {},
   "source": [
    "### Overview of Big Data ecosystem and tools\n",
    "\n",
    "The Big data ecosystem consists of a variety of tools designed for strong, processing, and analyzing massive dtasets. \n",
    "\n",
    "1. Hadoop: A framework for batch processing of large datasets.\n",
    "\n",
    "- Works by breaking down massive data into smaller chunks and processing them in paralle.\n",
    "- Ideal for scenarios where data can be processed in batches over time.\n",
    "- Example: Analyzing logs from a web server for monthly traffic trends.\n",
    "\n",
    "2. Spark: A fast and distributed computing framework.\n",
    "\n",
    "- Processes data in-memory, kaing it significantly faster than Hadoop for many tasks.\n",
    "- Can handle both batch and stream processing.\n",
    "- Example: Real-time fraud detection in financial transacations.\n",
    "\n",
    "3. NoSQL Databases: Designed for non-relational data storage and processing.\n",
    "    \n",
    "- Examples include MongoDB and Cassandra.\n",
    "- Suitable for flexible data models like documents, key-value pairs or wide-column stores.\n",
    "- Example: Storing user-generated content like reviews, images or log in a e-commerce system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d56469-692b-4c52-a2a1-500acf9a0ae4",
   "metadata": {},
   "source": [
    "#### Batch Processing vs. Stream Processing\n",
    "\n",
    "- Batch Processing:\n",
    "  - Data is collected over a period stored and processed in chunks.\n",
    "  - Tools like Hadoop are optimized for batch jobs.\n",
    "  - Example: Generating daily sales reports for a company.\n",
    "  - Pros: Suitable for large datasets that don't require immediate analysis.\n",
    "\n",
    "- Stream Processing:\n",
    "  - Data is processed in real time as it is generated.\n",
    "  - Tools like Spark Streaming are used for this purpose.\n",
    "  - Example: Monitoring stock prices and triggering alerts for anomalies.\n",
    "  - Pros: Enables real-time decision making for time sensitive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8445609-af6c-4401-b4bb-b2f38d367dfd",
   "metadata": {},
   "source": [
    "#### 1. Apache Spark\n",
    "- A fast and general-purpose cluster-computingsystem for large- scale data processing.\n",
    "\n",
    "2. Hadoop (HDFS & MapReduce)\n",
    "- A distributed storage and batch processing framework for big data.\n",
    "\n",
    "3. Apache Kafka\n",
    "-  A distributed event streaming platform for high-throughout real-time data pipelines.\n",
    "\n",
    "4. Tableau:\n",
    "- A powerful data visualization tool for creating interactive dashboards.\n",
    "\n",
    "5. Amazon S3:\n",
    "- A cloud-based object storage service for scalable and durable data storage.\n",
    "\n",
    "6. Google BigQuery:\n",
    "- A fully managed, serverless data warehouse for fast SQL anlaytics on large datasets.\n",
    "\n",
    "7. Power BI:\n",
    "- A business intelligence tool for data visualization and interactive reporting.\n",
    "\n",
    "8. Elascticsearch(ELK Stack):\n",
    "- A distributed search engine for real-time log analysis and monitoring.\n",
    "\n",
    "9. Pandas(Python):\n",
    "- A library for data manipulation and analysis with Python.\n",
    "\n",
    "10. Presto:\n",
    "- A distributed SQL query engine for running analytics on large data sets.\n",
    "\n",
    "11. Apache Cassandra:\n",
    "- A highly scalable NoSQL database for handling large volumes of structured data.\n",
    "\n",
    "12. Apache Flink:\n",
    "- A stream processing framework for real-time analytics.\n",
    "\n",
    "13. Apache Hive:\n",
    "- A data warehouse system for quering and analyzing large datasets using SQL.\n",
    "\n",
    "14. Apache Airflow:\n",
    "- A workflow orchestration tool for scheduling and automating data pipelines.\n",
    "\n",
    "15. Google Coud Dataflow:\n",
    "- A unified stream and batch processing system for real-time data pipelines.\n",
    "\n",
    "16. Apache Nifi:\n",
    "- A tool for automating and managing the flow of data between systems.\n",
    "\n",
    "17. R:\n",
    "- A programming language and environment for statistical computing and graphics.\n",
    "\n",
    "18. Tensorflow on Spark:\n",
    "- A framework for running deep learning workloads on Spark Clusters.\n",
    "\n",
    "19. Apache Mahout:\n",
    "- A sclabale machine learning library for clustering, classification and collaborative filtering.\n",
    "\n",
    "20. H2O.ai:\n",
    "- An open-source machine learning platform for scalble model training.\n",
    "\n",
    "21. Apache Oozie:\n",
    "- A workflow scheduler for managing Hadoop jobs.\n",
    "\n",
    "22. Talend:\n",
    "- A tool for ETL(Extract, Transform, Load) and data integration workflows.\n",
    "\n",
    "23. D3.js:\n",
    "- A JavaScript library for creating dynamics and interactive data visulaizations.\n",
    "\n",
    "24. Splunk:\n",
    "- A platform for analyzing machine-generated data to gain operational intelligence.\n",
    "\n",
    "25. Apache Ranger:\n",
    "- A security tool for managing access control in big data ecosystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d35512-d465-4998-9fe5-dadd165d3027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
